{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-06 07:16:44.586897: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-06 07:16:45.769118: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-06 07:16:54.515070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11421 MB memory:  -> device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "2024-01-06 07:16:54.516319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 11421 MB memory:  -> device: 1, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:05:00.0, compute capability: 6.1\n",
      "2024-01-06 07:16:54.517344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 11421 MB memory:  -> device: 2, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:08:00.0, compute capability: 6.1\n",
      "2024-01-06 07:16:54.518313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 11421 MB memory:  -> device: 3, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:09:00.0, compute capability: 6.1\n",
      "2024-01-06 07:16:54.519287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 11421 MB memory:  -> device: 4, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1\n",
      "2024-01-06 07:16:54.520319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 11421 MB memory:  -> device: 5, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:84:00.0, compute capability: 6.1\n",
      "2024-01-06 07:16:54.521370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 11421 MB memory:  -> device: 6, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:87:00.0, compute capability: 6.1\n",
      "2024-01-06 07:16:54.522354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 11421 MB memory:  -> device: 7, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:88:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 8\n",
      "Epoch 1/10\n",
      "INFO:tensorflow:Collective all_reduce tensors: 8 all_reduces, num_devices = 8, group_size = 8, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Collective all_reduce tensors: 8 all_reduces, num_devices = 8, group_size = 8, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-06 07:17:09.277208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2024-01-06 07:17:10.374094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2024-01-06 07:17:11.511285: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2024-01-06 07:17:12.440728: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2024-01-06 07:17:13.077992: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2024-01-06 07:17:13.781718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft:18442:18968 [0] NCCL INFO Bootstrap : Using enp13s0f0:172.17.4.53<0>\n",
      "soft:18442:18968 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-06 07:17:14.703302: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2024-01-06 07:17:15.504906: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft:18442:18979 [0] NCCL INFO cudaDriverVersion 11060\n",
      "NCCL version 2.13.4+cudaCUDA_MAJOR.CUDA_MINOR\n",
      "soft:18442:18994 [0] NCCL INFO NET/IB : No device found.\n",
      "soft:18442:18994 [0] NCCL INFO NET/Socket : Using [0]enp13s0f0:172.17.4.53<0> [1]br-dae752dcb0f0:172.24.0.1<0> [2]veth5b540b7:fe80::804d:6cff:fed2:a18a%veth5b540b7<0> [3]vethe5714be:fe80::74db:44ff:fed8:a269%vethe5714be<0> [4]veth39f21f7:fe80::6889:c5ff:fe9d:c70d%veth39f21f7<0> [5]vetha449a19:fe80::ce:5cff:feee:3f14%vetha449a19<0> [6]veth652d145:fe80::6c19:1bff:fe94:7970%veth652d145<0> [7]vetha93427a:fe80::4058:9dff:fe06:d483%vetha93427a<0>\n",
      "soft:18442:18994 [0] NCCL INFO Using network Socket\n",
      "soft:18442:18996 [2] NCCL INFO Using network Socket\n",
      "soft:18442:18997 [3] NCCL INFO Using network Socket\n",
      "soft:18442:18998 [4] NCCL INFO Using network Socket\n",
      "soft:18442:18999 [5] NCCL INFO Using network Socket\n",
      "soft:18442:19000 [6] NCCL INFO Using network Socket\n",
      "soft:18442:19001 [7] NCCL INFO Using network Socket\n",
      "soft:18442:18995 [1] NCCL INFO Using network Socket\n",
      "soft:18442:18996 [2] NCCL INFO Setting affinity for GPU 2 to 03ff,f0003fff\n",
      "soft:18442:19001 [7] NCCL INFO Setting affinity for GPU 7 to fffc00,0fffc000\n",
      "soft:18442:18995 [1] NCCL INFO Setting affinity for GPU 1 to 03ff,f0003fff\n",
      "soft:18442:18994 [0] NCCL INFO Setting affinity for GPU 0 to 03ff,f0003fff\n",
      "soft:18442:18998 [4] NCCL INFO Setting affinity for GPU 4 to fffc00,0fffc000\n",
      "soft:18442:19000 [6] NCCL INFO Setting affinity for GPU 6 to fffc00,0fffc000\n",
      "soft:18442:18999 [5] NCCL INFO Setting affinity for GPU 5 to fffc00,0fffc000\n",
      "soft:18442:18997 [3] NCCL INFO Setting affinity for GPU 3 to 03ff,f0003fff\n",
      "soft:18442:18996 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1\n",
      "soft:18442:18995 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0\n",
      "soft:18442:18994 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7\n",
      "soft:18442:18994 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7\n",
      "soft:18442:18995 [1] NCCL INFO P2P Chunksize set to 131072\n",
      "soft:18442:19001 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6\n",
      "soft:18442:18994 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1\n",
      "soft:18442:19001 [7] NCCL INFO P2P Chunksize set to 131072\n",
      "soft:18442:18997 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2\n",
      "soft:18442:18994 [0] NCCL INFO P2P Chunksize set to 131072\n",
      "soft:18442:18999 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4\n",
      "soft:18442:18999 [5] NCCL INFO P2P Chunksize set to 131072\n",
      "soft:18442:18997 [3] NCCL INFO P2P Chunksize set to 131072\n",
      "soft:18442:18996 [2] NCCL INFO P2P Chunksize set to 131072\n",
      "soft:18442:19000 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5\n",
      "soft:18442:18998 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3\n",
      "soft:18442:19000 [6] NCCL INFO P2P Chunksize set to 131072\n",
      "soft:18442:18998 [4] NCCL INFO P2P Chunksize set to 131072\n",
      "soft:18442:18998 [4] NCCL INFO Channel 00/0 : 4[83000] -> 5[84000] via P2P/direct pointer\n",
      "soft:18442:18996 [2] NCCL INFO Channel 00/0 : 2[8000] -> 3[9000] via P2P/direct pointer\n",
      "soft:18442:18999 [5] NCCL INFO Channel 00 : 5[84000] -> 6[87000] via SHM/direct/direct\n",
      "soft:18442:18997 [3] NCCL INFO Channel 00 : 3[9000] -> 4[83000] via SHM/direct/direct\n",
      "soft:18442:18995 [1] NCCL INFO Channel 00 : 1[5000] -> 2[8000] via SHM/direct/direct\n",
      "soft:18442:19001 [7] NCCL INFO Channel 00 : 7[88000] -> 0[4000] via SHM/direct/direct\n",
      "soft:18442:18996 [2] NCCL INFO Channel 01/0 : 2[8000] -> 3[9000] via P2P/direct pointer\n",
      "soft:18442:18998 [4] NCCL INFO Channel 01/0 : 4[83000] -> 5[84000] via P2P/direct pointer\n",
      "soft:18442:18994 [0] NCCL INFO Channel 00/0 : 0[4000] -> 1[5000] via P2P/direct pointer\n",
      "soft:18442:19000 [6] NCCL INFO Channel 00/0 : 6[87000] -> 7[88000] via P2P/direct pointer\n",
      "soft:18442:18999 [5] NCCL INFO Channel 01 : 5[84000] -> 6[87000] via SHM/direct/direct\n",
      "soft:18442:18997 [3] NCCL INFO Channel 01 : 3[9000] -> 4[83000] via SHM/direct/direct\n",
      "soft:18442:18995 [1] NCCL INFO Channel 01 : 1[5000] -> 2[8000] via SHM/direct/direct\n",
      "soft:18442:19001 [7] NCCL INFO Channel 01 : 7[88000] -> 0[4000] via SHM/direct/direct\n",
      "soft:18442:18994 [0] NCCL INFO Channel 01/0 : 0[4000] -> 1[5000] via P2P/direct pointer\n",
      "soft:18442:19000 [6] NCCL INFO Channel 01/0 : 6[87000] -> 7[88000] via P2P/direct pointer\n",
      "soft:18442:18998 [4] NCCL INFO Connected all rings\n",
      "soft:18442:18996 [2] NCCL INFO Connected all rings\n",
      "soft:18442:18995 [1] NCCL INFO Connected all rings\n",
      "soft:18442:18997 [3] NCCL INFO Connected all rings\n",
      "soft:18442:18994 [0] NCCL INFO Connected all rings\n",
      "soft:18442:18999 [5] NCCL INFO Connected all rings\n",
      "soft:18442:18995 [1] NCCL INFO Channel 00/0 : 1[5000] -> 0[4000] via P2P/direct pointer\n",
      "soft:18442:18998 [4] NCCL INFO Channel 00 : 4[83000] -> 3[9000] via SHM/direct/direct\n",
      "soft:18442:18997 [3] NCCL INFO Channel 00/0 : 3[9000] -> 2[8000] via P2P/direct pointer\n",
      "soft:18442:19000 [6] NCCL INFO Connected all rings\n",
      "soft:18442:19001 [7] NCCL INFO Connected all rings\n",
      "soft:18442:19001 [7] NCCL INFO Channel 00/0 : 7[88000] -> 6[87000] via P2P/direct pointer\n",
      "soft:18442:18996 [2] NCCL INFO Channel 00 : 2[8000] -> 1[5000] via SHM/direct/direct\n",
      "soft:18442:18995 [1] NCCL INFO Channel 01/0 : 1[5000] -> 0[4000] via P2P/direct pointer\n",
      "soft:18442:18998 [4] NCCL INFO Channel 01 : 4[83000] -> 3[9000] via SHM/direct/direct\n",
      "soft:18442:18997 [3] NCCL INFO Channel 01/0 : 3[9000] -> 2[8000] via P2P/direct pointer\n",
      "soft:18442:19001 [7] NCCL INFO Channel 01/0 : 7[88000] -> 6[87000] via P2P/direct pointer\n",
      "soft:18442:18996 [2] NCCL INFO Channel 01 : 2[8000] -> 1[5000] via SHM/direct/direct\n",
      "soft:18442:18999 [5] NCCL INFO Channel 00/0 : 5[84000] -> 4[83000] via P2P/direct pointer\n",
      "soft:18442:18994 [0] NCCL INFO Connected all trees\n",
      "soft:18442:18994 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "soft:18442:18994 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "soft:18442:18999 [5] NCCL INFO Channel 01/0 : 5[84000] -> 4[83000] via P2P/direct pointer\n",
      "soft:18442:19000 [6] NCCL INFO Channel 00 : 6[87000] -> 5[84000] via SHM/direct/direct\n",
      "soft:18442:18996 [2] NCCL INFO Connected all trees\n",
      "soft:18442:18996 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "soft:18442:18996 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "soft:18442:19000 [6] NCCL INFO Channel 01 : 6[87000] -> 5[84000] via SHM/direct/direct\n",
      "soft:18442:18997 [3] NCCL INFO Connected all trees\n",
      "soft:18442:18997 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "soft:18442:18997 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "soft:18442:18995 [1] NCCL INFO Connected all trees\n",
      "soft:18442:18995 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "soft:18442:18995 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "soft:18442:19001 [7] NCCL INFO Connected all trees\n",
      "soft:18442:19001 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "soft:18442:19001 [7] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "soft:18442:18998 [4] NCCL INFO Connected all trees\n",
      "soft:18442:18998 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "soft:18442:18998 [4] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "soft:18442:18999 [5] NCCL INFO Connected all trees\n",
      "soft:18442:18999 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "soft:18442:18999 [5] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "soft:18442:19000 [6] NCCL INFO Connected all trees\n",
      "soft:18442:19000 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\n",
      "soft:18442:19000 [6] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "soft:18442:18998 [4] NCCL INFO comm 0x7fcb18020740 rank 4 nranks 8 cudaDev 4 busId 83000 commId 0x871e780b7d1df116 - Init COMPLETE\n",
      "soft:18442:18994 [0] NCCL INFO comm 0x7fcb18009980 rank 0 nranks 8 cudaDev 0 busId 4000 commId 0x871e780b7d1df116 - Init COMPLETE\n",
      "soft:18442:18996 [2] NCCL INFO comm 0x7fcb18015060 rank 2 nranks 8 cudaDev 2 busId 8000 commId 0x871e780b7d1df116 - Init COMPLETE\n",
      "soft:18442:19000 [6] NCCL INFO comm 0x7fcb1802be20 rank 6 nranks 8 cudaDev 6 busId 87000 commId 0x871e780b7d1df116 - Init COMPLETE\n",
      "soft:18442:18997 [3] NCCL INFO comm 0x7fcb1801abd0 rank 3 nranks 8 cudaDev 3 busId 9000 commId 0x871e780b7d1df116 - Init COMPLETE\n",
      "soft:18442:19001 [7] NCCL INFO comm 0x7fcb18031990 rank 7 nranks 8 cudaDev 7 busId 88000 commId 0x871e780b7d1df116 - Init COMPLETE\n",
      "soft:18442:18995 [1] NCCL INFO comm 0x7fcb1800f4f0 rank 1 nranks 8 cudaDev 1 busId 5000 commId 0x871e780b7d1df116 - Init COMPLETE\n",
      "soft:18442:18999 [5] NCCL INFO comm 0x7fcb180262b0 rank 5 nranks 8 cudaDev 5 busId 84000 commId 0x871e780b7d1df116 - Init COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-06 07:17:17.438118: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe4cc10af70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-06 07:17:17.438171: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN X (Pascal), Compute Capability 6.1\n",
      "2024-01-06 07:17:17.438182: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA TITAN X (Pascal), Compute Capability 6.1\n",
      "2024-01-06 07:17:17.438189: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA TITAN X (Pascal), Compute Capability 6.1\n",
      "2024-01-06 07:17:17.438196: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA TITAN X (Pascal), Compute Capability 6.1\n",
      "2024-01-06 07:17:17.438203: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): NVIDIA TITAN X (Pascal), Compute Capability 6.1\n",
      "2024-01-06 07:17:17.438211: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (5): NVIDIA TITAN X (Pascal), Compute Capability 6.1\n",
      "2024-01-06 07:17:17.438218: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (6): NVIDIA TITAN X (Pascal), Compute Capability 6.1\n",
      "2024-01-06 07:17:17.438225: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (7): NVIDIA TITAN X (Pascal), Compute Capability 6.1\n",
      "2024-01-06 07:17:17.456612: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-06 07:17:17.657280: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - ETA: 0s - loss: 1.5239 - accuracy: 0.4511INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "782/782 [==============================] - 38s 23ms/step - loss: 1.5239 - accuracy: 0.4511 - val_loss: 1.2781 - val_accuracy: 0.5422\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.1762 - accuracy: 0.5869 - val_loss: 1.0877 - val_accuracy: 0.6189\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 1.0348 - accuracy: 0.6381 - val_loss: 0.9948 - val_accuracy: 0.6565\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 0.9408 - accuracy: 0.6727 - val_loss: 0.9768 - val_accuracy: 0.6559\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 0.8686 - accuracy: 0.6963 - val_loss: 0.9646 - val_accuracy: 0.6682\n",
      "Epoch 6/10\n",
      "216/782 [=======>......................] - ETA: 9s - loss: 0.8144 - accuracy: 0.7145"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:147\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m--> 147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:361\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;66;03m# cache_key_deletion_observer is useless here. It's based on all captures.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# A new cache key will be built later when saving ConcreteFunction because\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# only active captures should be saved.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m lookup_func_type, lookup_func_context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mmake_canonicalized_monomorphic_type(\n\u001b[1;32m    360\u001b[0m         args, kwargs, captures))\n\u001b[0;32m--> 361\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_func_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mlookup_func_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concrete_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    364\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function, filtered_flat_args\n",
      "File \u001b[0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/tensorflow/core/function/polymorphism/function_cache.py:48\u001b[0m, in \u001b[0;36mFunctionCache.lookup\u001b[0;34m(self, context, function_type)\u001b[0m\n\u001b[1;32m     46\u001b[0m   dispatch_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_dict[context]\u001b[38;5;241m.\u001b[39mdispatch(function_type)\n\u001b[1;32m     47\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dispatch_type:\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_primary\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdispatch_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/tensorflow/core/function/polymorphism/function_type.py:355\u001b[0m, in \u001b[0;36mFunctionType.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 355\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/tensorflow/core/function/trace_type/default_types.py:317\u001b[0m, in \u001b[0;36mList.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 317\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomponents_tuple\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data4/conda_envs/g2/lib/python3.8/site-packages/tensorflow/core/function/trace_type/default_types.py:244\u001b[0m, in \u001b[0;36mTuple.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 244\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomponents\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n",
    "os.environ[\"NCCL_DEBUG\"] = \"INFO\"\n",
    "# # export CUDA_HOME='/usr/local/cuda-10.1'\n",
    "# os.environ['CUDA_HOME'] ='/usr/local/cuda-11.5'\n",
    "# os.environ['PATH'] = '/usr/local/cuda-11.5/bin:' + os.environ['PATH']\n",
    "# os.environ['LIBRARY_PATH'] = '/usr/local/cuda-11.5/lib64:' + os.environ['LIBRARY_PATH']\n",
    "# os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda-11.5/lib64:'+ os.environ['LD_LIBRARY_PATH']\n",
    "# 使用设置好的环境变量\n",
    "# 加载 CIFAR-10 数据集\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# 归一化图像数据\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# 将目标变量转换为 one-hot 编码\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# 定义一个简单的 CNN 模型\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# 使用 MirroredStrategy 进行多 GPU 训练\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# 在策略范围内创建和编译模型\n",
    "with strategy.scope():\n",
    "    model = create_model()  \n",
    "    \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/data4/conda_envs/g2/bin:/usr/local/cuda-11.6/bin:/home/beihang/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/bin/remote-cli:/usr/bin:/data4/conda_envs/g2/bin:/sbin:/usr/local/cuda-10.1/bin:/home/beihang/anaconda3/bin:/home/beihang/anaconda3/condabin:/bin:/usr/bin:/usr/local/bin:/usr/local/cuda-10.1/bin:/home/beihang/anaconda3/bin:/bin:/usr/bin:/bin:/usr/bin:/usr/local/bin:/usr/local/cuda-10.1/bin:/home/beihang/anaconda3/bin:/bin:/usr/bin:/usr/local/cuda/bin:/snap/bin',\n",
       " '/usr/local/cuda-11.6')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['PATH'] ,os.environ['CUDA_HOME']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow can access CUDA\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"TensorFlow can access CUDA\")\n",
    "else:\n",
    "    print(\"TensorFlow cannot access CUDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
