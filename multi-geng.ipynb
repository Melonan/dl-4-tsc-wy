{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# # 修改一个已存在的环境变量\n",
    "# os.environ['PATH'] = '/usr/local/cuda-11.6/bin:' + os.environ['PATH']\n",
    "# os.environ['LIBRARY_PATH'] = '/usr/local/cuda-11.6/lib64:' + os.environ['LIBRARY_PATH']\n",
    "# os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda-11.6/lib64:'+ os.environ['LD_LIBRARY_PATH']\n",
    "# 使用设置好的环境变量\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n",
    "print(f\"PATH:{os.environ['PATH']}\\nCUDA_HOME:{os.environ['CUDA_HOME']}\")\n",
    "dataset_name = \"Kailuan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aeon.datasets.tsc_data_lists import multivariate_equal_length\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import sklearn\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time \n",
    "from utils import geng\n",
    "from utils.utils import create_directory\n",
    "from utils import logconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate_equal_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aeon.datasets import load_classification\n",
    "# import numpy as np\n",
    "# dataset_name = \"Libras\"\n",
    "# archive_name=\"MTS\"\n",
    "# X, Y,meta_data = load_classification(dataset_name,return_metadata=True)\n",
    "# X_reshaped = np.transpose(X, (0, 2, 1))\n",
    "# X = X_reshaped\n",
    "# nb_classes = len(np.unique(Y, axis=0))\n",
    "# nb_classes,X.shape,Y.shape,np.unique(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Kailuan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "archive_name=\"MTS\"\n",
    "time_series1 = pd.read_csv(\"./combined_sheets.csv\")\n",
    "time_series2 = pd.read_csv(\"./combined_sheets2.csv\")\n",
    "meta_data = pd.read_csv(\"./combinde170_info.csv\")\n",
    "time_series1.shape,time_series2.shape,meta_data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series2 = time_series2.drop(['SystolicPressure','DiastolicPressure'],axis=1)\n",
    "time_series = pd.concat([time_series1, time_series2], axis=0)\n",
    "time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movement全变成1 二值化\n",
    "# time_series['Movement'] = np.where(time_series['Movement'] != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造每个source的二维数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = time_series.groupby('Source')\n",
    "\n",
    "# 提取特征列\n",
    "features = [ 'Breath', 'Heartrate']\n",
    "\n",
    "# # 将每个组转换为二维数组并堆叠\n",
    "# three_dim_array = np.array([group[features].values for _, group in grouped])\n",
    "\n",
    "# three_dim_array.shape # 显示三维数组的形状"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movement 处理\n",
    "- Movement 取消： 只有fold3有提升 其他4个fold下降\n",
    "- Movement 全部+1 不行 都有下降\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_groupby = time_series.groupby('Source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看movement的分布\n",
    "# movement_stac=[{}]\n",
    "# for i in range(1,136):\n",
    "#     print(i)\n",
    "#     keys, vals = np.unique(time_groupby.get_group(int(i))[\"Movement\"].values,return_counts=True)\n",
    "#     result_dict = dict(zip(keys, vals))\n",
    "#     print(result_dict)\n",
    "#     movement_stac.append(result_dict)\n",
    "\n",
    "# # movement_stac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 填充 截断 时间序列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 填充/截断 构造数据集(去掉过少的)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial block \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新计算每个样例的时间步数（考虑到了数据过滤）\n",
    "filtered_time_steps_per_source = time_series.groupby('Source').size()\n",
    "\n",
    "# 重新筛选出有效的 Source 过滤掉过少的\n",
    "valid_sources = filtered_time_steps_per_source[filtered_time_steps_per_source > 500].index\n",
    "obsolete_sources = filtered_time_steps_per_source[filtered_time_steps_per_source <= 500].index\n",
    "print(\"valid sources:\", valid_sources, \"\\nobsolete sources:\", obsolete_sources, \"\\n len of obsoletes:\",filtered_time_steps_per_source[obsolete_sources])\n",
    "# 重新获取有效的数据\n",
    "valid_filtered_time_series = time_series[time_series['Source'].isin(valid_sources)]\n",
    "\n",
    "# 重新分组\n",
    "valid_filtered_grouped = valid_filtered_time_series.groupby('Source')\n",
    "\n",
    "# 重新计算平均时间步数（此时应该没有 NaN 值）\n",
    "average_time_steps = int(valid_filtered_grouped.size().mean())\n",
    "\n",
    "print(f\"\\n average_time_steps:{average_time_steps}\")\n",
    "\n",
    "# 初始化新的三维数组（考虑到了有效的样例数）\n",
    "valid_sources_count = len(valid_sources)\n",
    "three_dim_array_valid = np.zeros((valid_sources_count, average_time_steps, len(features)))\n",
    "\n",
    "# 填充新的三维数组\n",
    "for i, (source, group) in enumerate(valid_filtered_grouped):\n",
    "    data = group[features].values\n",
    "    current_steps = data.shape[0]\n",
    "    if current_steps < average_time_steps:\n",
    "        fill_values = {\n",
    "            'Breath': group['Breath'].mean(),\n",
    "            'Heartrate': group['Heartrate'].mean(),\n",
    "        }\n",
    "        fill_array = np.array([[fill_values[feature] for feature in features]] * (average_time_steps - current_steps))\n",
    "        full_data = np.vstack(( fill_array,data))\n",
    "    else:\n",
    "        # 调整为截取较后面的元素\n",
    "        full_data = data[current_steps-average_time_steps:, :]\n",
    "    # print(f\"source:{source},current_steps:{current_steps}, full_data shape:{full_data.shape}\")\n",
    "    three_dim_array_valid[i, :, :] = full_data\n",
    "\n",
    "\n",
    "final_data = three_dim_array_valid\n",
    "\n",
    "# 进行数据标准化\n",
    "final_data = geng.standard_scaler_total(final_data)\n",
    "\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标签构造\n",
    "- 意识状态\n",
    "- GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = meta_data[\"意识状态\"].values\n",
    "\n",
    "valid_sources = valid_sources-1\n",
    "labels = [labels[i] for i in range(len(labels)) if i in valid_sources]\n",
    "labels = [1 if x == 2 else x for x in labels]\n",
    "nb_classes = len(np.unique(labels, axis=0))\n",
    "labels = np.array(labels)\n",
    "labels, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (填充/截断)构造数据集 原本版 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# average_time_steps = int(grouped.apply(lambda x: x.shape[0]).mean())\n",
    "\n",
    "# # 初始化三维数组\n",
    "# features = ['Sleepstate', 'Breath', 'Heartrate', 'Movement']\n",
    "# three_dim_array = np.zeros((135, average_time_steps, len(features)))\n",
    "\n",
    "# # 填充三维数组\n",
    "# for source, group in grouped:\n",
    "#     data = group[features].values\n",
    "#     current_steps = data.shape[0]\n",
    "\n",
    "#     if current_steps < average_time_steps:\n",
    "#         fill_values = {\n",
    "#             'Breath': group['Breath'].mean(),\n",
    "#             'Heartrate': group['Heartrate'].mean(),\n",
    "#             'Sleepstate': group['Sleepstate'].median(),\n",
    "#             'Movement': 0\n",
    "#         }\n",
    "#         fill_array = np.array([[fill_values[feature] for feature in features]] * (average_time_steps - current_steps))\n",
    "#         full_data = np.vstack((data, fill_array))\n",
    "#     else:\n",
    "#         full_data = data[:average_time_steps, :]\n",
    "\n",
    "#     three_dim_array[source-1, :, :] = full_data\n",
    "\n",
    "# three_dim_array.shape  # 显示三维数组的形状\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标签构造\n",
    "- 意识状态\n",
    "- GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = meta_data[\"意识状态\"].values\n",
    "# nb_classes = len(np.unique(labels, axis=0))\n",
    "# labels,nb_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_final_process(x,y):\n",
    "    nb_classes = len(np.unique(y, axis=0))\n",
    "    # transform the labels from integers to one hot vectors\n",
    "    enc = sklearn.preprocessing.OneHotEncoder(categories='auto')\n",
    "    enc.fit(y.reshape(-1, 1))\n",
    "    y = enc.transform(y.reshape(-1, 1)).toarray()\n",
    "\n",
    "    # # save orignal y because later we will use binary\n",
    "    # y_true = np.argmax(y_test, axis=1)\n",
    "    print(f'x.shape: {x.shape}, y.shape: {y.shape}\\n')\n",
    "    if len(x.shape) == 2:  # if univariate\n",
    "        # add a dimension to make it multivariate with one dimension \n",
    "        x = x.reshape((x.shape[0], x.shape[1], 1))\n",
    "\n",
    "    input_shape = x.shape[1:]\n",
    "    print(f'input_shape: {input_shape}\\n')\n",
    "    \n",
    "    return x,y,input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_name=\"fcn\"\n",
    "root_dir=\"/data4/gsprivate/dl-4-tsc\"\n",
    "output_directory = root_dir + '/results/' + classifier_name + '/' + archive_name + '' + '/' + \\\n",
    "                    dataset_name + '/'\n",
    "                    \n",
    "if create_directory(output_directory) is None:\n",
    "    print(\"Creating directory:{} None\".format(output_directory))\n",
    "\n",
    "x,y,input_shape=data_final_process(final_data,labels)\n",
    "fcn_classifier = geng.create_classifier(classifier_name, input_shape, nb_classes, output_directory)\n",
    "print(f\"Classifier x.shape={x.shape} ,y.shape={y.shape}, input_shape={input_shape}, nb_classes={nb_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_name=\"cnn\"\n",
    "root_dir=\"/data4/gsprivate/dl-4-tsc\"\n",
    "output_directory = root_dir + '/results/' + classifier_name + '/' + archive_name + '' + '/' + \\\n",
    "                    dataset_name + '/'\n",
    "                    \n",
    "if create_directory(output_directory) is None:\n",
    "    print(\"Creating directory:{} None\".format(output_directory))\n",
    "\n",
    "x,y,input_shape=data_final_process(final_data,labels)\n",
    "cnn_classifier = geng.create_classifier(classifier_name, input_shape, nb_classes, output_directory)\n",
    "print(f\"Classifier x.shape={x.shape} ,y.shape={y.shape}, input_shape={input_shape}, nb_classes={nb_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_name=\"mcnn\"\n",
    "root_dir=\"/data4/gsprivate/dl-4-tsc\"\n",
    "output_directory = root_dir + '/results/' + classifier_name + '/' + archive_name + '' + '/' + \\\n",
    "                    dataset_name + '/'\n",
    "                    \n",
    "if create_directory(output_directory) is None:\n",
    "    print(\"Creating directory:{} None\".format(output_directory))\n",
    "\n",
    "x,y,input_shape=data_final_process(final_data,labels)\n",
    "mcnn_classifier = geng.create_classifier(classifier_name, input_shape, nb_classes, output_directory)\n",
    "print(f\"Classifier x.shape={x.shape} ,y.shape={y.shape}, input_shape={input_shape}, nb_classes={nb_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# %%capture cap --no-stderr\n",
    "# print(\"这将写入到文件中\")\n",
    "logconfig.setup_logging(dir=\"/data4/gsprivate/dl-4-tsc/results/mcnn/MTS/Kailuan\")\n",
    "geng.fit_splits_for_mcnn(mcnn_classifier,x,y,epochs=250)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geng.fit_splits(cnn_classifier,x,y,batch_size=8,epochs=200)\n",
    "# print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch \n",
    "import tensorflow as tf\n",
    "\n",
    "# print(torch.version.cuda)·\n",
    "# print(torch.backends.cudnn.version())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Retrieving all environment variables\n",
    "# env_vars = os.environ\n",
    "\n",
    "# # Displaying the environment variables\n",
    "# env_vars_dict = {key: env_vars[key] for key in env_vars}\n",
    "# env_vars_dict['LD_LIBRARY_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsprivate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
